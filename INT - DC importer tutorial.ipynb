{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to write a Digital Connector importer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim is to write an importer for fetching Body Mass Index for the obese (BMI - 30/39.9 kg/m^2) data from Sports England website, to be used within the Tombolo Digital Connector framework. The data comes as a downloadable .csv file at a local authority level for the whole UK. Our importer will essentially do the following:\n",
    "\n",
    "\n",
    "* Fetch the dataset from the relevant link. The link is the result of a query that we have already made online using Sport England’s Active People Interactive query builder. Although Tombolo Digital Connector importers allow for a dynamic query building framework we will be using a simple hardcoded link to fetch the data set.\n",
    "\n",
    "* Import the attributes of interest and assign the correct geometry for every local authority in our dataset.\n",
    "\n",
    "* Save the data in the Digital Connector Postgres database. The correct formatting and housekeeping will be done automatically by the DC.\n",
    "\n",
    "Once our importer is ready, we will be able to use it in all our Digital Connector recipes. Note that there is already a generic csv importer that can be used in this case, but for the sake of demonstration we will implement the importer step-by-step as the implementation generalises to other data types (excel files, json files etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some wordbusting that i will be using throughout this tutorial:\n",
    " * **Subject**: You can think of this as a row in our dataset. A DC subject is an object having attributes such as ID, name, and most importantly a spatial extent or Geometry\n",
    " * **Attribute**: You can think of this as the columns in our dataset. This is an object that essentially holds the names of our columns along with some other metadata about our columns (such as description). The attributes will appear in our Postgres database as we named them during importing.\n",
    " * **Values**: The actual values in the dataset for a particular attribute that we want to import.\n",
    " \n",
    "I will be using IntelliJ IDEA for this tutorial. IntelliJ IDEA is a free Java IDE that has lots of cool functionalities (such as autocomplete, class references, syntax checking, etc.) that will make our lives easier. A few assumptions at this point:\n",
    "\n",
    "* You have downloaded and installed IntelliJ IDEA \n",
    "* You have cloned the Tombolo Digital Connector repo and successfully installed all the dependencies\n",
    "* You have basic coding experience preferably with Java\n",
    "\n",
    "I will be using lots of gifs in this tutorial because they’re great.\n",
    "\n",
    "***Lets get started!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the data from Sport England\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Go to Sport England query builder http://activepeople.sportengland.org/Query and click Physical Activity/Geographies/Local Authorities/select all/OK. \n",
    "* Select Local authorities and click OK\n",
    "* Now click Measures/Body Mass Index (BMI)/Obese/OK\n",
    "* No click the GO icon which will navigate you to the data\n",
    "* We need the link to the data. To get that right click on Export table as CSV and click copy link. The link to the query is: \n",
    "\n",
    "http://activepeople.sportengland.org/Result/ExportTable?Id=101891&TabDimension=1&RowDimension=2&ColDimension=4&SelectedTabs[0]=39991&ValueMode=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifsImporterTut/output_wKg9Hy.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"gifsImporterTut/output_wKg9Hy.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the importer Java class in IntelliJ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open IntelliJ and navigate to the TomboloDigitalConnector folder. Under importer right click and create a new package (this is essentially a folder that will hold our importer classes). Name your package as sportsen (stands for Sports England)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifsImporterTut/output_tAne7U.gif\" height=\"500\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"gifsImporterTut/output_tAne7U.gif\" height=\"500\" width=\"500\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a java class by right clicking on the newly created sportsen folder and \n",
    " click new java class. Name this as ObeseImporter. You will be asked if you want to \n",
    " add the file to Git, say no for the time being\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifsImporterTut/output_HNkL2I.gif\" height=\"500\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"gifsImporterTut/output_HNkL2I.gif\" height=\"500\" width=\"500\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create all the methods necessary for the importer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we start getting in the meat of things! A TomboloDigitalConnector importer is a java class that inherits all the methods from the AbstractImporter class which do all the necessary housekeeping needed for data crunching. \n",
    "\n",
    "* We need to specify this inheritance structure of our importer we do this \n",
    "     by extending the ObeseImporter class. IntelliJ can save us the trouble of \n",
    " writing everything manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifsImporterTut/output_YH0qSo.gif\" height=\"500\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"gifsImporterTut/output_YH0qSo.gif\" height=\"500\" width=\"500\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice (from the red underlying) that we are not quite there yet. For our class to inherit all methods from the AbstractImporter class we need to implemend a config method that matches the same method of the AbstractImporter class. To check out what methods are implemented in the AbstractImporter class you can always cmd + b on the line that you want to know more about. This will navigate you to the relevant code within DC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifsImporterTut/output_Leel21.gif\" height=\"500\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"gifsImporterTut/output_Leel21.gif\" height=\"500\" width=\"500\">')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the code looks like in the end:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```java\n",
    "public class ObeseImporter extends AbstractImporter {\n",
    "    public ObeseImporter(Config config) {\n",
    "        super(config);\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public Provider getProvider() {\n",
    "        return null;\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public DatasourceSpec getDatasourceSpec(String datasourceId) throws Exception {\n",
    "        return null;\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    protected void importDatasource(Datasource datasource, List<String> geographyScope, List<String> temporalScope, List<String> datasourceLocation) throws Exception {\n",
    "\n",
    "    }\n",
    "}\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to break things down:\n",
    "*     \n",
    "```java\n",
    "public Provider getProvider()\n",
    "```\n",
    "You can think of this method as the metadata for our data provider. It takes two arguments, a label and a name. These can be whatever you want, but its *very* good practice to make it as informative as possible. Usually the label is the general url of the dataset source and the label is the datasource's provider name. In our case, we got the website from activepeople.sportengland.org and the name will be Sports England. We implement that by making a Provider object with those attributes, which we then pass to the getProvider() method:\n",
    "\n",
    "```java\n",
    "    protected static final Provider PROVIDER = new Provider(\n",
    "            \"activepeople.sportengland.org\",\n",
    "            \"Sports England\"\n",
    "    );\n",
    "    \n",
    "    @Override\n",
    "    public Provider getProvider() {\n",
    "        return PROVIDER;\n",
    "    }    \n",
    "```\n",
    "\n",
    " \n",
    "```java\n",
    "public DatasourceSpec getDatasourceSpec(String datasourceId)\n",
    "```\n",
    "\n",
    "This method is specifying our datasource specifications. It takes as arguments a datasourceId as string, which will be the datasourceId you will be calling the specific dataset of the importer through the recipe file. We do this by implementing a DatasourceSpec with arguments the importer class, the name of the datasource, an ID, a description, and the dataset url:\n",
    "\n",
    "\n",
    "\n",
    "```java\n",
    "    @Override\n",
    "    public DatasourceSpec getDatasourceSpec(String datasourceId) throws Exception {\n",
    "        DatasourceSpec datasourceSpec = new DatasourceSpec(\n",
    "                ObeseImporter.class,\n",
    "                \"BMIObese\",\n",
    "                \"BMI Obese\",\n",
    "                \"% of people with BMI 30-39.9 kg/m^2\",\n",
    "                DATASOURCE);\n",
    "        return datasourceSpec;\n",
    "    }\n",
    "```\n",
    "Note the <span style=\"color:purple\">***DATASOURCE***</span>  variable. This is a string contains the link to our dataset (.csv file). This could also be the path to the local file if there was one. We need to include it in our importer:\n",
    "```java\n",
    "    private static final String DATASOURCE = \"http://activepeople.sportengland.org/Result/ExportTable?Id=134820&TabDimension=2&RowDimension=1&ColDimension=4&SelectedTabs[0]=10&ValueMode=0\";\n",
    "```\n",
    "Finally we need to add the datasourceId in our config constructor. This way we can call this through our recipe language:\n",
    "\n",
    "```java\n",
    "    public ObeseImporter(Config config) {\n",
    "        super(config);\n",
    "        try {\n",
    "            datasourceIds = Arrays.asList(getDatasourceSpec(\"BMIObese\").getId());\n",
    "        } catch (Exception e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "```\n",
    "There is a final piece of the puzzle that we haven't addressed yet: \n",
    "```java\n",
    "    @Override\n",
    "    protected void importDatasource(Datasource datasource, List<String> geographyScope, List<String> temporalScope, List<String> datasourceLocation) throws Exception {\n",
    "\n",
    "    }\n",
    "```\n",
    "\n",
    "\n",
    "This method is the meat of the importer so we will dedicate a special step in the tutorial for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implement the importDatasource method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far were mainly doing housekeeping. Now we will implement the code that reads our dataset file, assigns geometry to subjects, defines te attributes and imports the values. Note that we need to have an understanding on how our data are represented in the dataset and in what format are represented (eg. text, numbers) etc.\n",
    "\n",
    "The best way to do this is by looking at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gifsImporterTut/Screen Shot 2017-12-13 at 14.47.34.png\" height=\"1000\" width=\"1000\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"gifsImporterTut/Screen Shot 2017-12-13 at 14.47.34.png\" height=\"1000\" width=\"1000\">')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the dataset is very unstructured. There are superflous lines, values encoded as strings where there shouldn't, local authorities having no spatial extent.\n",
    "\n",
    "Let's take things one at a time:\n",
    "\n",
    "* First we need to specify placeholder objects for our SubjectType which will hold the geometry of our observations. As you noticed, we only have the local authority name without any geometry information. We can get that information by querring DC's OaImporter. Before we get to do that we need to instantiate it:\n",
    "\n",
    "```java\n",
    "    @Override\n",
    "    protected void importDatasource(Datasource datasource, List<String> geographyScope, List<String> temporalScope, List<String> datasourceLocation) throws Exception {\n",
    "       SubjectType localauthority = SubjectTypeUtils.getOrCreate(AbstractONSImporter.PROVIDER,\n",
    "                        OaImporter.OaType.localAuthority.name(),   OaImporter.OaType.localAuthority.datasourceSpec.getDescription());\n",
    "\n",
    "    }\n",
    "```\n",
    "* Then we need to download the dataset and pass it to an object. We do that by instantiating the format, grab the URL from the getDatasourceSpec(\"BMIObese\") method we defined and pass it into an InputStreamReader object. Here we are using the DownloadUtils class of DC that lets us access the fetchInputStream method that takes care the downloading bit. Once the importer is ready, you can check whether the .csv file was downloaded succesfully by looking your in your /tmp/TomboloData folder. If everything went OK, DC should have assigned a unique ID (SHA-key) for that file: \n",
    "\n",
    "```java\n",
    "//// more code...\n",
    "\n",
    "    @Override\n",
    "    protected void importDatasource(Datasource datasource, List<String> geographyScope, List<String> temporalScope, List<String> datasourceLocation) throws Exception {\n",
    "    \n",
    "        // We create SubjectType object that we will use to get the appropriate geometries\n",
    "        // from OaImporter class\n",
    "       SubjectType localauthority = SubjectTypeUtils.getOrCreate(AbstractONSImporter.PROVIDER,\n",
    "                        OaImporter.OaType.localAuthority.name(),   OaImporter.OaType.localAuthority.datasourceSpec.getDescription());\n",
    "                        \n",
    "                        \n",
    "        // The code below fetches the .csv file from the URL we specified in our DatasourceSpec object\n",
    "        CSVFormat format = CSVFormat.DEFAULT;\n",
    "        String fileLocation = getDatasourceSpec(\"BMIObese\").getUrl();\n",
    "\n",
    "        URL url;\n",
    "        try {\n",
    "            url = new URL(fileLocation);\n",
    "        } catch (MalformedURLException e) {\n",
    "            File file;\n",
    "            if (!(file = new File(fileLocation)).exists()) {\n",
    "                System.out.println(\"ERROR: File does not exist: \" + fileLocation);\n",
    "            }\n",
    "            url = file.toURI().toURL();\n",
    "        }\n",
    "\n",
    "        InputStreamReader isr = new InputStreamReader(\n",
    "                downloadUtils.fetchInputStream(url, getProvider().getLabel(), \".csv\"));\n",
    "                \n",
    "        // Parsing our csv file\n",
    "        CSVParser csvFileParser = new CSVParser(isr, format);\n",
    "        csvRecords = csvFileParser.getRecords();\n",
    "\n",
    "    }\n",
    "    \n",
    "//// more code...\n",
    "\n",
    "```\n",
    "\n",
    "Before we finish with this step, we need to instantiate a list for our csvRecords. We do that on the top level of our importer:\n",
    "\n",
    "```java\n",
    "public class ObeseImporter extends AbstractImporter {\n",
    "\n",
    "    // Instantiating the list that will hold our .csv rows\n",
    "    private List csvRecords;\n",
    "//// more code...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now its time to import the dataset in the Postgres database. First, we need to create a list that will hold our vaules. To keep things simple, we will use the FixedValue type for this particular dataset:\n",
    "\n",
    "\n",
    "```java\n",
    "//// more code...\n",
    "    @Override\n",
    "    protected void importDatasource(Datasource datasource, List<String> geographyScope, List<String> temporalScope, List<String> datasourceLocation) throws Exception {\n",
    "    \n",
    "        // We create SubjectType object that we will use to get the appropriate geometries\n",
    "        // from OaImporter class\n",
    "        SubjectType localauthority = SubjectTypeUtils.getOrCreate(AbstractONSImporter.PROVIDER,\n",
    "                OaImporter.OaType.localAuthority.name(), OaImporter.OaType.localAuthority.datasourceSpec.getDescription());\n",
    "\n",
    "        // We create an empty list that will keep our .csv values\n",
    "        List<FixedValue> fixedValues = new ArrayList<FixedValue>();\n",
    "        \n",
    "//// more code...\n",
    "```\n",
    "\n",
    "* Next, we define our Attributes (column names). We do this by implementing a getFixedValueAttributes method in our importer. This will simply assign a name for each of the columns of interest in our dataset. In this case, we have essentially 3 columns of interest: The BMI obesity percentages for different time periods. We exclude the local authorities name as we will fetch that using DC's OAImporter:\n",
    "\n",
    "```java\n",
    "//// more code...\n",
    "    @Override\n",
    "    public List<Attribute> getFixedValueAttributes(String datasourceID) {\n",
    "        // Creating a placeholder for our attributes\n",
    "        List<Attribute> attributes = new ArrayList<>();\n",
    "        \n",
    "        // Dataset specific: we hardcode the columns names for the our .csv file\n",
    "        String[] elements = { \"BMI_obesity_2013\", \"BMI_obesity_2014\", \"BMI_obesity_2015\"};\n",
    "\n",
    "        // We loop through the elements of the elements object and adding an Attribute object in the list \n",
    "        // with nour column names.\n",
    "        for( int i = 0; i < elements.length; i++) {\n",
    "            attributes.add(new Attribute(getProvider(), elements[i], elements[i]));\n",
    "\n",
    "        }\n",
    "        return attributes;\n",
    "    }\n",
    "\n",
    "//// more code...\n",
    "\n",
    "```\n",
    "\n",
    "Note that instead of hardcoding the column names we could have read them from our .csv file instead. \n",
    "\n",
    "\n",
    "* Then, we create the loop that will read through the .csv lines and pass them in the appropriate placeholders (Attribute for the name of the column, and fixedValues for the actual values of the .csv). You will see lots of try/catch clauses to account for the inconsistencies in the dataset:  \n",
    "```java\n",
    "//// more code...\n",
    "    // We discard the first 6 records in our data file as these don't hold any meaningfull information.\n",
    "        // We do this  calling an iterator object and simply ignoring them:\n",
    "        Iterator<CSVRecord> rowIterator = csvRecords.iterator();\n",
    "\n",
    "        // skipping first 6 rows\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "\n",
    "        // Looping through the rows of the .csv file\n",
    "        while (rowIterator.hasNext()){\n",
    "            CSVRecord row = rowIterator.next();\n",
    "\n",
    "            // Fetching the subject geometry from OaImporter to save it in getFixedValueAttributes. Note that this\n",
    "            // corresponds to the 3rd element of our row: row.get(2).\n",
    "            try{\n",
    "                Subject subject = SubjectUtils.getSubjectByTypeAndName(localauthority, String.valueOf(row.get(2)).trim());\n",
    "\n",
    "                // Checking not matched geometries\n",
    "                if (subject!=null){\n",
    "                    // Dataset specific: attributeIndex is the column index that we are interested in.\n",
    "                    int attributeIndex = 3;\n",
    "\n",
    "                    // The value is a string in our .csv file. We need to clean it and convert it to a number\n",
    "                    // We need to check for invalid rows so we will suround this with a try catch clause\n",
    "                    try {\n",
    "                        String record = row.get(attributeIndex).replace(\"%\",\"\");\n",
    "\n",
    "                        // We discard the rows that contain no values. In the .csv these are depicted as '*'\n",
    "                        if (!Objects.equals(record, \"*\")){\n",
    "                            System.out.println(record);\n",
    "                            \n",
    "                            // The value is a string in our .csv file. We need to clean it and convert it to a \n",
    "                            // number. We need to check for invalid rows so we will suround this \n",
    "                            // with a try catch clause\n",
    "                            for (Attribute attribute : datasource.getFixedValueAttributes()) {\n",
    "                                fixedValues.add(new FixedValue(\n",
    "                                        subject,\n",
    "                                        attribute,\n",
    "                                        record));\n",
    "\n",
    "                                // We increment to get the rest of the values in the row\n",
    "                                attributeIndex++;\n",
    "\n",
    "                            }\n",
    "                        }\n",
    "                    } catch (ArrayIndexOutOfBoundsException npe) {\n",
    "                        System.out.println(\"INFO - Found invalid row: Skipping\");\n",
    "\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                else {\n",
    "                    System.out.println(\"INFO - Geometry not found for \"+ row.get(2) + \": Skipping\");\n",
    "                    continue;\n",
    "                }\n",
    "            }\n",
    "            // We need to check for again for invalid rows when looping through the local authorities names\n",
    "            catch (ArrayIndexOutOfBoundsException npe){\n",
    "                System.out.println(\"INFO - Found invalid local authority row: Skipping\");\n",
    "                continue;\n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "        // Finally we save the values in the database\n",
    "        FixedValueUtils.save(fixedValues);\n",
    "        fixedValues.clear();\n",
    "//// more code...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **And that's it we are finished! Below is the full importer class**\n",
    "```java\n",
    "package uk.org.tombolo.importer.sportsen;\n",
    "\n",
    "\n",
    "/**\n",
    " * Created by tbantis on 13/12/2017.\n",
    " */\n",
    "public class ObeseImporter extends AbstractImporter {\n",
    "\n",
    "    // Instantiating the list that will hold our .csv rows\n",
    "    private List csvRecords;\n",
    "    \n",
    "    // Instantiating the link to our .csv file\n",
    "    private static final String DATASOURCE = \"http://activepeople.sportengland.org/Result/ExportTable?Id=134820&TabDimension=2&RowDimension=1&ColDimension=4&SelectedTabs[0]=10&ValueMode=0\";\n",
    "\n",
    "    // Instantiating the AbstractImporter constructor\n",
    "    public ObeseImporter(Config config) {\n",
    "        super(config);\n",
    "        try {\n",
    "            // Specifying the datasourceId. This will be used by the DC recipe\n",
    "            datasourceIds = Arrays.asList(getDatasourceSpec(\"BMIObese\").getId());\n",
    "        } catch (Exception e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Instantiating the data Provider\n",
    "    protected static final Provider PROVIDER = new Provider(\n",
    "            \"activepeople.sportengland.org\",\n",
    "            \"Sports England\"\n",
    "    );\n",
    "\n",
    "    // Getting the data Provider\n",
    "    @Override\n",
    "    public Provider getProvider() {\n",
    "        return PROVIDER;\n",
    "    }\n",
    "\n",
    "    // Instantiating the datasoure specifications. \n",
    "    @Override\n",
    "    public DatasourceSpec getDatasourceSpec(String datasourceId) throws Exception {\n",
    "        DatasourceSpec datasourceSpec = new DatasourceSpec(\n",
    "                ObeseImporter.class,\n",
    "                \"BMIObese\",\n",
    "                \"BMI Obese\",\n",
    "                \"% of people with BMI 30-39.9 kg/m^2\",\n",
    "                DATASOURCE);\n",
    "        return datasourceSpec;\n",
    "    }\n",
    "\n",
    "    // The method that does the data  fetching, cleaning, reformatting and importing\n",
    "    @Override\n",
    "    protected void importDatasource(Datasource datasource, List<String> geographyScope, List<String> temporalScope, List<String> datasourceLocation) throws Exception {\n",
    "\n",
    "        // We create SubjectType object that we will use to get the appropriate geometries\n",
    "        // from OaImporter class\n",
    "        SubjectType localauthority = SubjectTypeUtils.getOrCreate(AbstractONSImporter.PROVIDER,\n",
    "                OaImporter.OaType.localAuthority.name(), OaImporter.OaType.localAuthority.datasourceSpec.getDescription());\n",
    "\n",
    "        // We create an empty list that will keep our .csv values\n",
    "        List<FixedValue> fixedValues = new ArrayList<FixedValue>();\n",
    "\n",
    "        CSVFormat format = CSVFormat.DEFAULT;\n",
    "        String fileLocation = getDatasourceSpec(\"BMIObese\").getUrl();\n",
    "\n",
    "        // The code below fetches the .csv file from the URL we specified in our DatasourceSpec object\n",
    "        URL url;\n",
    "        try {\n",
    "            url = new URL(fileLocation);\n",
    "        } catch (MalformedURLException e) {\n",
    "            File file;\n",
    "            if (!(file = new File(fileLocation)).exists()) {\n",
    "                System.out.println(\"ERROR: File does not exist: \" + fileLocation);\n",
    "            }\n",
    "            url = file.toURI().toURL();\n",
    "        }\n",
    "\n",
    "        InputStreamReader isr = new InputStreamReader(\n",
    "                downloadUtils.fetchInputStream(url, getProvider().getLabel(), \".csv\"));\n",
    "\n",
    "        // Parsing our csv file\n",
    "        CSVParser csvFileParser = new CSVParser(isr, format);\n",
    "        csvRecords = csvFileParser.getRecords();\n",
    "\n",
    "\n",
    "        // We discard the first 6 records in our data file as these don't hold any meaningfull information.\n",
    "        // We do this  calling an iterator object and simply ignoring them:\n",
    "        Iterator<CSVRecord> rowIterator = csvRecords.iterator();\n",
    "\n",
    "        // skipping first 6 rows\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "        rowIterator.next();\n",
    "\n",
    "        // Looping through the rows of the .csv file\n",
    "        while (rowIterator.hasNext()){\n",
    "            CSVRecord row = rowIterator.next();\n",
    "\n",
    "            // Fetching the subject geometry from OaImporter to save it in getFixedValueAttributes. Note that this\n",
    "            // corresponds to the 3rd element of our row: row.get(2).\n",
    "            try{\n",
    "                Subject subject = SubjectUtils.getSubjectByTypeAndName(localauthority, String.valueOf(row.get(2)).trim());\n",
    "\n",
    "                // Checking not matched geometries\n",
    "                if (subject!=null){\n",
    "                    // Dataset specific: attributeIndex is the column index that we are interested in.\n",
    "                    int attributeIndex = 3;\n",
    "\n",
    "                    // The value is a string in our .csv file. We need to clean it before using it.\n",
    "                    // We  need to check for invalid rows so we will suround this with a try catch clause\n",
    "                    try {\n",
    "                        String record = row.get(attributeIndex).replace(\"%\",\"\");\n",
    "\n",
    "                        // We discard the rows that contain no values. In the .csv these are depicted as '*'\n",
    "                        if (!Objects.equals(record, \"*\")){\n",
    "                            System.out.println(record);\n",
    "                            // Here is where we are assigning the values of our .csv file to the attribute fields we\n",
    "                            // created.\n",
    "                            for (Attribute attribute : datasource.getFixedValueAttributes()) {\n",
    "                                fixedValues.add(new FixedValue(\n",
    "                                        subject,\n",
    "                                        attribute,\n",
    "                                        record));\n",
    "\n",
    "                                // We increment to get the rest of the values in the row\n",
    "                                attributeIndex++;\n",
    "\n",
    "                            }\n",
    "                        }\n",
    "                    // Catching invalid rows\n",
    "                    } catch (ArrayIndexOutOfBoundsException npe) {\n",
    "                        System.out.println(\"INFO - Found invalid row: Skipping\");\n",
    "\n",
    "                    }\n",
    "                }\n",
    "                // Catching invalid geometries\n",
    "                else {\n",
    "                    System.out.println(\"INFO - Geometry not found for \"+ row.get(2) + \": Skipping\");\n",
    "                    continue;\n",
    "                }\n",
    "            }\n",
    "            // We need to check for again for invalid rows when looping through the local authorities names\n",
    "            catch (ArrayIndexOutOfBoundsException npe){\n",
    "                System.out.println(\"INFO - Found invalid local authority row: Skipping\");\n",
    "                continue;\n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "        // Finally we save the values in the database\n",
    "        FixedValueUtils.save(fixedValues);\n",
    "        fixedValues.clear();\n",
    "\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public List<Attribute> getFixedValueAttributes(String datasourceID) {\n",
    "        // Creating a placeholder for our attributes\n",
    "        List<Attribute> attributes = new ArrayList<>();\n",
    "\n",
    "        // Dataset specific: we hardcode the columns names for the our .csv file\n",
    "        String[] elements = { \"BMI_obesity_2013\", \"BMI_obesity_2014\", \"BMI_obesity_2015\"};\n",
    "\n",
    "        // We loop through the elements of the elements object and adding an Attribute object in the list\n",
    "        // with nour column names.\n",
    "        for( int i = 0; i < elements.length; i++) {\n",
    "            attributes.add(new Attribute(getProvider(), elements[i], elements[i]));\n",
    "\n",
    "        }\n",
    "        return attributes;\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you could use this importer in a recipe:\n",
    "```java\n",
    "  {\n",
    "  \"dataset\": {\n",
    "    \"subjects\": [\n",
    "      {\n",
    "        \"subjectType\": \"localAuthority\",\n",
    "        \"provider\": \"uk.gov.ons\"\n",
    "        ,\n",
    "        \"matchRule\": {\n",
    "          \"attribute\": \"label\",\n",
    "          \"pattern\": \"E090000%\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"datasources\": [\n",
    "      {\n",
    "        \"importerClass\": \"uk.org.tombolo.importer.ons.OaImporter\",\n",
    "        \"datasourceId\": \"localAuthority\"\n",
    "      },\n",
    "      {\n",
    "        \"importerClass\": \"uk.org.tombolo.importer.sportsen.ObeseImporter\",\n",
    "        \"datasourceId\": \"BMIObese\"\n",
    "\n",
    "      }\n",
    "\n",
    "    ],\n",
    "    \"fields\": [\n",
    "      {\n",
    "\n",
    "          \"fieldClass\": \"uk.org.tombolo.field.value.FixedValueField\",\n",
    "          \"label\": \"BMI_obesity_2013\",\n",
    "          \"attribute\": {\n",
    "            \"provider\": \"activepeople.sportengland.org\",\n",
    "            \"label\": \"BMI_obesity_2013\"\n",
    "        }\n",
    "     }\n",
    "    ]\n",
    "  },\n",
    "    \"exporter\": \"uk.org.tombolo.exporter.GeoJsonExporter\"\n",
    "}\n",
    "    \n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
